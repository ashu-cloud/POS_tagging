{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hEfbvGjxWi5",
        "outputId": "d16f97dc-522a-4344-f4ed-6e3e4196eea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "#from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import re\n",
        "import copy\n",
        "#import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import random #for shuffling list\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "dataset = brown.tagged_sents(tagset='universal')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import json\n",
        "info = api.info()\n",
        "print(json.dumps(info, indent=4))\n",
        "print(api.load('word2vec-google-news-300', return_path=True))"
      ],
      "metadata": {
        "id": "DtYuFQ38GCRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)"
      ],
      "metadata": {
        "id": "Jy947tqUGEIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unknown_word(word, train_set): #Cosine Similarity\n",
        "    try:\n",
        "        word_vec = w2v_model.wv[word]\n",
        "    except:\n",
        "        word_vec = np.random.rand(300)\n",
        "    min = -1 #index\n",
        "    value = -1 \n",
        "    for i in range(len(train_set)):\n",
        "        try:\n",
        "            train_vec = w2v_model.wv[i]\n",
        "        except:\n",
        "            train_vec = np.random.rand(300)\n",
        "        norm = np.linalg.norm(word_vec)*np.linalg.norm(train_vec)\n",
        "        dot = np.dot(train_vec, word_vec)\n",
        "        if dot/norm > value:\n",
        "            value = dot/norm\n",
        "            min = i\n",
        "    return train_set[i]"
      ],
      "metadata": {
        "id": "2QmIpLTJQRGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "l = []\n",
        "\n",
        "#sentences = list(brown.tagged_sents(tagset='universal'))\n",
        "sentences = list(dataset)\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    test = sentences[i]\n",
        "    test.insert(0, (\"^\", \"START\"))\n",
        "    test.append((\"$\", \"END\"))\n",
        "    sentences[i] = test\n",
        "    for j in sentences[i]:\n",
        "        l.append(j)\n",
        "    \n",
        "tags = {}\n",
        "for i in l:\n",
        "    if i[1] not in tags:\n",
        "        tags[i[1]] = [i[0]]\n",
        "    else:\n",
        "        tags[i[1]].append(i[0])\n",
        "\n",
        "words = {}\n",
        "for i in l:\n",
        "    wrd = i[0]\n",
        "    if wrd not in words:\n",
        "        words[wrd] = [i[1]]\n",
        "    else:\n",
        "        words[wrd].append(i[1])\n",
        "\n",
        "tag_list = list(tags.keys())\n",
        "print(tag_list)\n",
        "exit()\n",
        "\n",
        "#Calculating P(tag|word)\n",
        "p_tag_given_word = {}\n",
        "for tag in tag_list:\n",
        "    for wrd in words:\n",
        "        p_tag_given_word[( tag, wrd )] = words[wrd].count(tag)/len(words[wrd]) #Word with given tag count / total count of the word 'wrd' in the corpus\n",
        "\n",
        "p_word_given_tag = {}\n",
        "for tag in p_tag_given_word:\n",
        "    p_word_given_tag[ tag[::-1] ] = p_tag_given_word[tag] * ( len(words[ tag[1] ])/len(l) ) / ( len(tags[ tag[0] ])/len(l) )\n",
        "\n",
        "#Transition Probabilities P(tag -> tag)\n",
        "p_tag_to_tag = {}\n",
        "\n",
        "for item in sentences:\n",
        "    for g in range(len(item)-1):\n",
        "        if ( item[g][1], item[g+1][1] ) not in p_tag_to_tag:\n",
        "            p_tag_to_tag[( item[g][1], item[g+1][1] )] = 1.0\n",
        "        else:\n",
        "            p_tag_to_tag[( item[g][1], item[g+1][1] )] += 1.0 #P(noun -> verb) += 1, we store count here\n",
        "\n",
        "for t in p_tag_to_tag:\n",
        "    p_tag_to_tag[t] /= len(tags[t[0]]) #P(noun -> verb) /= num(nouns)\n",
        "\n",
        "for tag in tag_list:\n",
        "    p_tag_to_tag[(tag, 'START')] = 0.0\n",
        "    p_tag_to_tag[('END', tag)] = 0.0\n",
        "p_tag_to_tag[('START', 'END')] = 0.0\n",
        "\n",
        "\n",
        "#---------------------VITERBI-------------------------\n",
        "\n",
        "actual_tags = []\n",
        "predicted_tags = []\n",
        "\n",
        "#print(len(all_sentences))\n",
        "all_tags = tag_list \n",
        "\n",
        "transition_matrix=np.random.rand(len(all_tags),len(all_tags))\n",
        "for i in range(len(all_tags)):\n",
        "    for j in range(len(all_tags)):\n",
        "        try:\n",
        "            transition_matrix[i][j] = p_tag_to_tag[(all_tags[i], all_tags[j])]\n",
        "        except:\n",
        "            transition_matrix[i][j]=0.0\n",
        "transition_matrix=transition_matrix.astype('float64')#(transition_matrix)\n",
        "\n",
        "all_tokens = list(words.keys())\n",
        "\n",
        "lexical_probs=np.random.rand(len(all_tags),len(all_tokens))\n",
        "for i in range(len(all_tags)):\n",
        "    for j in range(len(all_tokens)):\n",
        "        try:\n",
        "            lexical_probs[i][j] = p_word_given_tag[(all_tokens[j], all_tags[i])]\n",
        "        except:\n",
        "            lexical_probs[i][j]=0.0\n",
        "lexical_probs=lexical_probs.astype('float64')#(lexical_probs)\n",
        "\n",
        "#-------------------------------------------------------------------------------------\n",
        "given_sent = \"The long and lonely road to Mumbai.\"\n",
        "token_ex = token_ex = re.findall(r\"([\\w'-]+|[.,!?\\[\\]\\(\\);:]|[`]+)\", given_sent)\n",
        "token_ex.insert(0, \"^\")\n",
        "token_ex.append(\"$\")\n",
        "\n",
        "for index in range(len(token_ex)):\n",
        "    wrd = token_ex[index]\n",
        "    if not wrd in words:\n",
        "        assign = unknown_word(wrd, list(words.keys())) #has cosine similarity calculated\n",
        "        token_ex[index] = assign\n",
        "\n",
        "prob_matrix=np.array([[0.0]*len(all_tags)]*len(all_tags))\n",
        "for i in range(len(token_ex)-1):\n",
        "    if i==0:\n",
        "        prev_tag=\"START\"\n",
        "        transition_probs=np.array([transition_matrix[all_tags.index(prev_tag)][j] for j in range(len(all_tags))])\n",
        "        obs_prob=lexical_probs[all_tags.index(prev_tag)][all_tokens.index(token_ex[i])]\n",
        "        net_probs=obs_prob*transition_probs\n",
        "        seq=[[\"START\",all_tags[k]] for k in range(0,len(all_tags))]\n",
        "\n",
        "    else:\n",
        "        for k in range(0,len(all_tags)):\n",
        "            transition_probs=np.array([transition_matrix[k][j] for j in range(len(all_tags))])\n",
        "            obs_prob=lexical_probs[k][all_tokens.index(token_ex[i])]\n",
        "            prob_matrix[k]=obs_prob*net_probs[k]*transition_probs\n",
        "\n",
        "        new_seq=[[] for s in range(len(all_tags))]\n",
        "        for k in range(0,len(all_tags)):\n",
        "            a=prob_matrix[:,k].max\n",
        "            idx=np.argmax(prob_matrix[:,k])\n",
        "            new_seq[k]=copy.deepcopy(seq[idx])\n",
        "            new_seq[k].append(all_tags[k])\n",
        "            net_probs[k]=prob_matrix[idx][k]\n",
        "        seq=copy.deepcopy(new_seq)\n",
        "\n",
        "predicted = seq[1]\n",
        "for i in range(len(token_ex)):\n",
        "    print(token_ex[i], predicted[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3uQuRJfdwth",
        "outputId": "aae450ff-e5e0-47c5-ccd1-74aa4c87b2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['START', 'DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'END', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X']\n",
            "^ START\n",
            "The DET\n",
            "long ADJ\n",
            "and CONJ\n",
            "lonely ADJ\n",
            "road NOUN\n",
            "to PRT\n",
            "stupefying VERB\n",
            ". .\n",
            "$ DET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_decoding(training_sentences, testing_sentences):\n",
        "\n",
        "    l = []\n",
        "\n",
        "    #sentences = list(brown.tagged_sents(tagset='universal'))\n",
        "    sentences = list(training_sentences)\n",
        "\n",
        "    for i in range(len(sentences)):\n",
        "        test = sentences[i]\n",
        "        test.insert(0, (\"^\", \"START\"))\n",
        "        test.append((\"$\", \"END\"))\n",
        "        sentences[i] = test\n",
        "        for j in sentences[i]:\n",
        "            l.append(j)\n",
        "        \n",
        "    tags = {}\n",
        "    for i in l:\n",
        "        if i[1] not in tags:\n",
        "            tags[i[1]] = [i[0]]\n",
        "        else:\n",
        "            tags[i[1]].append(i[0])\n",
        "\n",
        "    words = {}\n",
        "    for i in l:\n",
        "        wrd = i[0]\n",
        "        if wrd not in words:\n",
        "            words[wrd] = [i[1]]\n",
        "        else:\n",
        "            words[wrd].append(i[1])\n",
        "\n",
        "    tag_list = list(tags.keys())\n",
        "    print(tag_list)\n",
        "    exit()\n",
        "\n",
        "    #Calculating P(tag|word)\n",
        "    p_tag_given_word = {}\n",
        "    for tag in tag_list:\n",
        "        for wrd in words:\n",
        "            p_tag_given_word[( tag, wrd )] = words[wrd].count(tag)/len(words[wrd]) #Word with given tag count / total count of the word 'wrd' in the corpus\n",
        "\n",
        "    p_word_given_tag = {}\n",
        "    for tag in p_tag_given_word:\n",
        "        p_word_given_tag[ tag[::-1] ] = p_tag_given_word[tag] * ( len(words[ tag[1] ])/len(l) ) / ( len(tags[ tag[0] ])/len(l) )\n",
        "\n",
        "    #Transition Probabilities P(tag -> tag)\n",
        "    p_tag_to_tag = {}\n",
        "\n",
        "    for item in sentences:\n",
        "        for g in range(len(item)-1):\n",
        "            if ( item[g][1], item[g+1][1] ) not in p_tag_to_tag:\n",
        "                p_tag_to_tag[( item[g][1], item[g+1][1] )] = 1.0\n",
        "            else:\n",
        "                p_tag_to_tag[( item[g][1], item[g+1][1] )] += 1.0 #P(noun -> verb) += 1, we store count here\n",
        "\n",
        "    for t in p_tag_to_tag:\n",
        "        p_tag_to_tag[t] /= len(tags[t[0]]) #P(noun -> verb) /= num(nouns)\n",
        "\n",
        "    for tag in tag_list:\n",
        "        p_tag_to_tag[(tag, 'START')] = 0.0\n",
        "        p_tag_to_tag[('END', tag)] = 0.0\n",
        "    p_tag_to_tag[('START', 'END')] = 0.0\n",
        "    \n",
        "\n",
        "    #---------------------VITERBI-------------------------\n",
        "\n",
        "    actual_tags = []\n",
        "    predicted_tags = []\n",
        "\n",
        "    #print(len(all_sentences))\n",
        "    all_tags = tag_list \n",
        "\n",
        "    transition_matrix=np.random.rand(len(all_tags),len(all_tags))\n",
        "    for i in range(len(all_tags)):\n",
        "        for j in range(len(all_tags)):\n",
        "            try:\n",
        "                transition_matrix[i][j] = p_tag_to_tag[(all_tags[i], all_tags[j])]\n",
        "            except:\n",
        "                transition_matrix[i][j]=0.0\n",
        "    transition_matrix=transition_matrix.astype('float64')#(transition_matrix)\n",
        "\n",
        "    all_tokens = list(words.keys())\n",
        "\n",
        "    lexical_probs=np.random.rand(len(all_tags),len(all_tokens))\n",
        "    for i in range(len(all_tags)):\n",
        "        for j in range(len(all_tokens)):\n",
        "            try:\n",
        "                lexical_probs[i][j] = p_word_given_tag[(all_tokens[j], all_tags[i])]\n",
        "            except:\n",
        "                lexical_probs[i][j]=0.0\n",
        "    lexical_probs=lexical_probs.astype('float64')#(lexical_probs)\n",
        "\n",
        "    for iter in range( len(testing_sentences) ):\n",
        "\n",
        "        #given_sent = ' '.join([str(elem[0]) for elem in testing_sentences[iter]])\n",
        "        actual_tag_sent = []\n",
        "        actual_tag_sent = testing_sentences[iter]\n",
        "\n",
        "        actual_tag_sent.insert(0, (\"^\", \"START\"))\n",
        "        actual_tag_sent.append((\"$\", \"END\"))\n",
        "        actual_tags.append([i[1] for i in actual_tag_sent])\n",
        "\n",
        "        token_ex = [i[0] for i in actual_tag_sent]\n",
        "        \n",
        "        for index in range(len(token_ex)):\n",
        "            wrd = token_ex[index]\n",
        "            if not wrd in words:\n",
        "                assign = unknown_word(wrd, list(words.keys())) #has cosine similarity calculated\n",
        "                token_ex[index] = assign\n",
        "\n",
        "        prob_matrix=np.array([[0.0]*len(all_tags)]*len(all_tags))\n",
        "        for i in range(len(token_ex)-1):\n",
        "            if i==0:\n",
        "                prev_tag=\"START\"\n",
        "                transition_probs=np.array([transition_matrix[all_tags.index(prev_tag)][j] for j in range(len(all_tags))])\n",
        "                obs_prob=lexical_probs[all_tags.index(prev_tag)][all_tokens.index(token_ex[i])]\n",
        "                net_probs=obs_prob*transition_probs\n",
        "                seq=[[\"START\",all_tags[k]] for k in range(0,len(all_tags))]\n",
        "\n",
        "            else:\n",
        "                for k in range(0,len(all_tags)):\n",
        "                    transition_probs=np.array([transition_matrix[k][j] for j in range(len(all_tags))])\n",
        "                    obs_prob=lexical_probs[k][all_tokens.index(token_ex[i])]\n",
        "                    prob_matrix[k]=obs_prob*net_probs[k]*transition_probs\n",
        "\n",
        "                new_seq=[[] for s in range(len(all_tags))]\n",
        "                for k in range(0,len(all_tags)):\n",
        "                    a=prob_matrix[:,k].max\n",
        "                    idx=np.argmax(prob_matrix[:,k])\n",
        "                    new_seq[k]=copy.deepcopy(seq[idx])\n",
        "                    new_seq[k].append(all_tags[k])\n",
        "                    net_probs[k]=prob_matrix[idx][k]\n",
        "                seq=copy.deepcopy(new_seq)\n",
        "\n",
        "        predicted_tags.append(seq[1])\n",
        "    \n",
        "    actual_total=[]\n",
        "    predicted_total=[]\n",
        "    for i in range(len(actual_tags)):\n",
        "        for j in range(len(actual_tags[i])):\n",
        "            actual_total.append(actual_tags[i][j])\n",
        "            predicted_total.append(predicted_tags[i][j])\n",
        "    \n",
        "    print(confusion_matrix(actual_total, predicted_total))\n",
        "    return actual_tags, predicted_tags"
      ],
      "metadata": {
        "id": "akM0GYbFHKAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_per_fold(training_sentences, test_sentences):\n",
        "    test_y,predictions = sentence_decoding(training_sentences, test_sentences)\n",
        "\n",
        "    f1 = 0\n",
        "    prec = 0\n",
        "    recall = 0\n",
        "    \n",
        "\n",
        "    #for i in range( len(actual_tags) ):\n",
        "    #    f1 += f1_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    prec += precision_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    recall += recall_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    per_pos=[[] for i in range(12)]\n",
        "    #per_pos_act=[[] for i in range(0,12)]\n",
        "    for i in range(len(test_y)):\n",
        "        per_pos[test_y[i]].append(predictions[i])\n",
        "    print(\"my_fold------------------------\")\n",
        "    for i in range(len(per_pos)):\n",
        "        print(i,\"-----\")\n",
        "        true_tag=[i for j in range(len(per_pos[i]))]\n",
        "        print(\"precision\",precision_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"recall\",recall_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"f1\",f1_score(per_pos[i],true_tag, average='weighted'))\n",
        "    print(\"overall for the batch:\")\n",
        "    precision=precision_score(test_y,predictions, average='weighted')\n",
        "    recall=recall_score(test_y,predictions, average='weighted')\n",
        "    f1=f1_score(test_y,predictions, average='weighted')\n",
        "    print(\"precision\",precision)\n",
        "    print(\"recall\",recall)\n",
        "    print(\"f1\",f1)\n",
        "\n",
        "        \n",
        "    return [precision, recall, f1]\n",
        "    #return [f1/len(actual_tags), prec/len(actual_tags), recall/len(actual_tags)]\n",
        "\n",
        "#total_acc_for_split1 = accuracy_per_fold(all_sentences[:57000], all_sentences[56000:56010])\n",
        "#total_acc_for_split2 = accuracy_per_fold(all_sentences[:57000], all_sentences[57000:57010])\n",
        "\n",
        "#print(\"\\nTotal accuracy for the above split1: \" + str(total_acc_for_split1))\n",
        "#print(\"Total accuracy for the above split2: \" + str(total_acc_for_split2) + \"\\n\")\n",
        "#exit(0)\n",
        "\n",
        "def cross_validation_accuracy(all_sentences = dataset):\n",
        "    all_accuracies = []\n",
        "    total_acc = [0, 0, 0]\n",
        "\n",
        "    num_sentences = len(dataset)\n",
        "\n",
        "    fold_size = int(num_sentences / 5)\n",
        "\n",
        "    print(fold_size)\n",
        "\n",
        "    fold1_train=dataset[:4*fold_size]\n",
        "    fold1_test=dataset[4*fold_size:]\n",
        "    fold2_train=dataset[:3*fold_size]+dataset[4*fold_size:]\n",
        "    fold2_test=dataset[3*fold_size:4*fold_size]\n",
        "    fold3_train=dataset[:2*fold_size]+dataset[3*fold_size:]\n",
        "    fold3_test=dataset[2*fold_size:3*fold_size]\n",
        "    fold4_train=dataset[:1*fold_size]+dataset[2*fold_size:]\n",
        "    fold4_test=dataset[1*fold_size:2*fold_size]\n",
        "    fold5_train=dataset[1*fold_size:]\n",
        "    fold5_test=dataset[:1*fold_size]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold1_train, fold1_test))\n",
        "    print(\"Accuracy for fold \", \"1\", \" is : \", str(all_accuracies[0]))\n",
        "    total_acc[0] += all_accuracies[0][0]\n",
        "    total_acc[1] += all_accuracies[0][1]\n",
        "    total_acc[2] += all_accuracies[0][2]\n",
        "\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold2_train, fold2_test))\n",
        "    print(\"Accuracy for fold \", \"2\", \" is : \", str(all_accuracies[1]))\n",
        "    total_acc[0] += all_accuracies[1][0]\n",
        "    total_acc[1] += all_accuracies[1][1]\n",
        "    total_acc[2] += all_accuracies[1][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold3_train, fold3_test))\n",
        "    print(\"Accuracy for fold \", \"3\", \" is : \", str(all_accuracies[2]))\n",
        "    total_acc[0] += all_accuracies[2][0]\n",
        "    total_acc[1] += all_accuracies[2][1]\n",
        "    total_acc[2] += all_accuracies[2][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold4_train, fold4_test))\n",
        "    print(\"Accuracy for fold \", \"4\", \" is : \", str(all_accuracies[3]))\n",
        "    total_acc[0] += all_accuracies[3][0]\n",
        "    total_acc[1] += all_accuracies[3][1]\n",
        "    total_acc[2] += all_accuracies[3][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold5_train, fold5_test))\n",
        "    print(\"Accuracy for fold \", \"5\", \" is : \", str(all_accuracies[4]))\n",
        "    total_acc[0] += all_accuracies[4][0]\n",
        "    total_acc[1] += all_accuracies[4][1]\n",
        "    total_acc[2] += all_accuracies[4][2]\n",
        "\n",
        "    print(\"Cross validation accuracy is : \", str(np.array(total_acc) / 5))"
      ],
      "metadata": {
        "id": "B1bLO5FKGLpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation_accuracy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "Z1MenpR7Gek7",
        "outputId": "63345492-d0a8-4e95-fc0b-7a20ad45c971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11468\n",
            "['START', 'DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'END', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-020e01285662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_validation_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-6d56590dbb88>\u001b[0m in \u001b[0;36mcross_validation_accuracy\u001b[0;34m(all_sentences)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfold5_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mall_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_per_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy for fold \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" is : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtotal_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mall_accuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6d56590dbb88>\u001b[0m in \u001b[0;36maccuracy_per_fold\u001b[0;34m(training_sentences, test_sentences)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy_per_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_decoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-62037aed302b>\u001b[0m in \u001b[0;36msentence_decoding\u001b[0;34m(training_sentences, testing_sentences)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mwrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0massign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munknown_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#has cosine similarity calculated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0mtoken_ex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unknown_word' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "_y-HnoWpRpQ_",
        "outputId": "6f9a82bb-63e1-46c4-944a-8505b554547a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6ecbef3605b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
          ]
        }
      ]
    }
  ]
}