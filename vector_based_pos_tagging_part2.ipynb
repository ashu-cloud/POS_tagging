{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "806483ee",
        "outputId": "68c3edf0-3678-418b-a86d-c0064f643d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "#from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import re\n",
        "import copy\n",
        "#import numpy as np\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import random #for shuffling list\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import gensim\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "dataset = brown.tagged_sents(tagset='universal')"
      ],
      "id": "806483ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb702796"
      },
      "outputs": [],
      "source": [
        "# tags_and_words=brown.tagged_words(tagset='universal')\n",
        "# print(len(tags_and_words))"
      ],
      "id": "cb702796"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad49a67c"
      },
      "outputs": [],
      "source": [
        "#train_tagged_sents,val_tagged_sents=train_test_split(dataset,test_size=0.2,random_state=40)\n",
        "#val_sents,test_sents=train_test_split(remaining,test_size=0.1,train_size=0.2,random_state=40)"
      ],
      "id": "ad49a67c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YXjBS0lig-k",
        "outputId": "d2731387-1411-479b-ba66-c03d595437a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "import json\n",
        "info = api.info()\n",
        "#print(json.dumps(info, indent=4))\n",
        "print(api.load('word2vec-google-news-300', return_path=True))"
      ],
      "id": "0YXjBS0lig-k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqcTtS3gkRMU"
      },
      "outputs": [],
      "source": [
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)"
      ],
      "id": "EqcTtS3gkRMU"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "xJ9Vvxf6hNGS"
      },
      "id": "xJ9Vvxf6hNGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b3c6c6b",
        "outputId": "66861e9e-d2d8-4162-dc3f-0b70c86225a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "180\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "# a=[]\n",
        "# for sent in dataset:\n",
        "#     a.append(len(sent))\n",
        "# print(max(a))\n",
        "# print(min(a))"
      ],
      "id": "5b3c6c6b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2d4267f"
      },
      "outputs": [],
      "source": [
        "def get_feature_dataset_train(train_tagged_sents):  \n",
        "    #words_and_tags = brown.tagged_sents(tagset='universal')\n",
        "\n",
        "    words_in_corpus = []\n",
        "    tags_in_corpus = []\n",
        "\n",
        "    for tagged_sent in train_tagged_sents:\n",
        "        for item in tagged_sent:\n",
        "            words_in_corpus.append(item[0])\n",
        "            tags_in_corpus.append(item[1])\n",
        "\n",
        "    words_in_corpus = list(set(words_in_corpus))\n",
        "    tags_in_corpus = list(set(tags_in_corpus))\n",
        "\n",
        "    words_in_corpus.sort()\n",
        "    tags_in_corpus.sort()\n",
        "\n",
        "    print(len(words_in_corpus))\n",
        "    print(tags_in_corpus)\n",
        "\n",
        "    word_dictionary = dict()\n",
        "    tag_dictionary = dict()\n",
        "\n",
        "    for i in range ( len(tags_in_corpus) ):\n",
        "        tag_dictionary[tags_in_corpus[i]] = i # 0 based indexing of IDs\n",
        "\n",
        "    for i in range ( len(words_in_corpus) ):\n",
        "        word_dictionary[words_in_corpus[i]] = i # 0 based indexing of IDs\n",
        "\n",
        "    index_for_word_not_in_corpus = len(words_in_corpus)\n",
        "    \n",
        "    def suffix_features(word): #input is the string form of word\n",
        "\n",
        "        features = []\n",
        "        flag = False\n",
        "\n",
        "        # ---- x ---- Noun Suffix ---- x ----\n",
        "        noun_suffixes = ['acy', 'al', 'ance', 'ence', 'dom', 'er', 'or', 'ism',\n",
        "                         'ist', 'ity', 'ty', 'ment', 'ness', 'ship', 'sion',\n",
        "                         'tion', 'ct']\n",
        "\n",
        "        for i in noun_suffixes:\n",
        "            if len(re.findall(i+\"$\", word)) > 0:\n",
        "                flag = True\n",
        "                break\n",
        "\n",
        "        if flag :\n",
        "            features.append(1)\n",
        "        else: \n",
        "            features.append(0)\n",
        "\n",
        "        flag = False\n",
        "\n",
        "        # ---- x ---- Verb Suffix ---- x ----\n",
        "        verb_suffixes = ['es', 'ed', 'ate', 'en', 'ify', 'fy', 'ize', 'ise',\n",
        "                         'ers', 'ingly']\n",
        "\n",
        "        for i in verb_suffixes:\n",
        "            if len(re.findall(i+\"$\", word)) > 0:\n",
        "                flag = True\n",
        "                break\n",
        "\n",
        "        if flag :\n",
        "            features.append(1)\n",
        "        else: \n",
        "            features.append(0)\n",
        "\n",
        "        flag = False\n",
        "\n",
        "        # ---- x ---- Adjective Suffix ---- x ----\n",
        "        adj_suffixes = ['able', 'ible', 'al', 'esque', 'ful', 'ic', 'ical',\n",
        "                        'ious', 'ous', 'ish', 'ive', 'less', 'y']\n",
        "\n",
        "        for i in adj_suffixes:\n",
        "            if len(re.findall(i+\"$\", word)) > 0:\n",
        "                flag = True\n",
        "                break\n",
        "\n",
        "        if flag :\n",
        "            features.append(1)\n",
        "        else: \n",
        "            features.append(0)\n",
        "\n",
        "\n",
        "        return features\n",
        "\n",
        "    def feature_matrix(sentence, tag_list):\n",
        "\n",
        "        assert len(sentence) == len(tag_list)\n",
        "\n",
        "        n = len(sentence)\n",
        "        f_mat = []\n",
        "        y_arr=[]\n",
        "        for i in range (n):\n",
        "            f_word = []\n",
        "\n",
        "            # ------ x ------ 1st feature - ID of word in dictionary ------ x ------\n",
        "\n",
        "            f_word.append(word_dictionary[sentence[i]])\n",
        "\n",
        "            # ------ x ------ 2nd feature - ID of previous word in dictionary ------ x ------\n",
        "\n",
        "            if i != 0 : #valid if it is not the first word\n",
        "                f_word.append(word_dictionary[sentence[i - 1]])\n",
        "            else:\n",
        "                f_word.append(-1)\n",
        "\n",
        "            # ------ x ------ 3rd feature - ID of next word in dictionary ------ x ------\n",
        "\n",
        "            if i != n - 1 : #valid if it is not the last word\n",
        "                f_word.append(word_dictionary[sentence[i + 1]])\n",
        "            else:\n",
        "                f_word.append(-1)        \n",
        "\n",
        "            # ------ x ------ 4th feature - POS tag of previous word ------ x ------\n",
        "\n",
        "            if i!=0: #valid if it is not the first word\n",
        "                f_word.append(tag_dictionary[tag_list[i-1]])\n",
        "            else:\n",
        "                f_word.append(-1)\n",
        "\n",
        "            # ------ x ------ 5th, 6th and 7th feature - Noun, Verb and Adjective suffix check of current word ------ x ------\n",
        "\n",
        "            f_word = f_word + suffix_features(sentence[i])\n",
        "            #print(str(len(f_word)) + \"    \" + str(len(suffix_features(sentence[i]))))\n",
        "\n",
        "            # ------ x ------ 8th, 9th and 10th feature - Noun, Verb and Adjective suffix check of previous word ------ x ------\n",
        "\n",
        "            if i != 0 : #valid if it is not the first word\n",
        "                f_word = f_word + suffix_features(sentence[i - 1])\n",
        "            else:\n",
        "                f_word = f_word + [-1, -1, -1]\n",
        "\n",
        "            # ------ x ------ 11th, 12th and 13th feature - Noun, Verb and Adjective suffix check of next word ------ x ------\n",
        "\n",
        "            if i != n - 1 : #valid if it is not the last word\n",
        "                f_word = f_word + suffix_features(sentence[i + 1])\n",
        "            else:\n",
        "                f_word = f_word + [-1, -1, -1]\n",
        "                \n",
        "            # ------ x ------ pos tag of current word as y ------ x ------\n",
        "            y_arr.append(tag_dictionary[tag_list[i]])\n",
        "            \n",
        "            f_mat.append(f_word)\n",
        "            #print(len(f_word))\n",
        "\n",
        "        return f_mat,y_arr\n",
        "    \n",
        "    train_mat=[]\n",
        "    train_y=[]\n",
        "    for tagged_sent in train_tagged_sents:\n",
        "        sentence=[]\n",
        "        tag_list=[]\n",
        "        for item in tagged_sent:\n",
        "            sentence.append(item[0])\n",
        "            tag_list.append(item[1])\n",
        "        f_mat,y_arr=feature_matrix(sentence,tag_list)\n",
        "        train_mat+=f_mat\n",
        "        train_y+=y_arr\n",
        "    return train_mat,train_y"
      ],
      "id": "b2d4267f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64f4a80d",
        "outputId": "a50b2156-967e-410c-8b81-109fd229d718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50647\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
          ]
        }
      ],
      "source": [
        "# train_mat,train_y=get_feature_dataset_train(train_tagged_sents)"
      ],
      "id": "64f4a80d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsGSEPZwndAE"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "#global failed\n",
        "#failed=0\n",
        "def get_feature_dataset_train_w2v(train_tagged_sents):\n",
        "    # failed=0\n",
        "    # total=0  \n",
        "    #words_and_tags = brown.tagged_sents(tagset='universal')\n",
        "\n",
        "    words_in_corpus = []\n",
        "    tags_in_corpus = []\n",
        "\n",
        "    for tagged_sent in train_tagged_sents:\n",
        "        for item in tagged_sent:\n",
        "            words_in_corpus.append(item[0])\n",
        "            tags_in_corpus.append(item[1])\n",
        "\n",
        "    words_in_corpus = list(set(words_in_corpus))\n",
        "    tags_in_corpus = list(set(tags_in_corpus))\n",
        "\n",
        "    words_in_corpus.sort()\n",
        "    tags_in_corpus.sort()\n",
        "\n",
        "    print(len(words_in_corpus))\n",
        "    print(tags_in_corpus)\n",
        "\n",
        "    word_dictionary = dict()\n",
        "    tag_dictionary = dict()\n",
        "\n",
        "    for i in range ( len(tags_in_corpus) ):\n",
        "        tag_dictionary[tags_in_corpus[i]] = i # 0 based indexing of IDs\n",
        "\n",
        "    for i in range ( len(words_in_corpus) ):\n",
        "        word_dictionary[words_in_corpus[i]] = i # 0 based indexing of IDs\n",
        "\n",
        "    index_for_word_not_in_corpus = len(words_in_corpus)\n",
        "    \n",
        "    \n",
        "\n",
        "    def feature_matrix(sentence, tag_list):\n",
        "        # failed=0\n",
        "        # total=0\n",
        "        assert len(sentence) == len(tag_list)\n",
        "\n",
        "        n = len(sentence)\n",
        "        f_mat = []\n",
        "        y_arr=[]\n",
        "        for i in range(n):\n",
        "            # total+=1\n",
        "            try:\n",
        "                f_mat.append(w2v_model[sentence[i]])\n",
        "                #f_mat.append(w2v_model.wv[sentence[i]])\n",
        "                y_arr.append(tag_dictionary[tag_list[i]])\n",
        "            except:\n",
        "                # failed+=1\n",
        "                #pass\n",
        "                #f_mat.append(np.random.normal(loc=0.0,scale=0.1,size=300))\n",
        "                #f_mat.append(w2v_model.wv[sentence[i]])\n",
        "                #y_arr.append(tag_dictionary[tag_list[i]])\n",
        "                \n",
        "                f_mat.append(np.random.normal(loc=0.0,scale=0.1,size=300))\n",
        "                y_arr.append(tag_dictionary[tag_list[i]])\n",
        "\n",
        "            # ------ x ------ pos tag of current word as y ------ x ------\n",
        "            #y_arr.append(tag_dictionary[tag_list[i]])\n",
        "            \n",
        "            #f_mat.append(w2v_model.wv[sentence[i]])\n",
        "            #print(len(f_word))\n",
        "\n",
        "        return f_mat,y_arr\n",
        "    \n",
        "    train_mat=[]\n",
        "    train_y=[]\n",
        "    \n",
        "    for tagged_sent in train_tagged_sents:\n",
        "        sentence=[]\n",
        "        tag_list=[]\n",
        "        for item in tagged_sent:\n",
        "            sentence.append(item[0])\n",
        "            tag_list.append(item[1])\n",
        "        f_mat,y_arr=feature_matrix(sentence,tag_list)\n",
        "        \n",
        "        train_mat+=f_mat\n",
        "        train_y+=y_arr\n",
        "    return train_mat,train_y"
      ],
      "id": "IsGSEPZwndAE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5IGZ1zoZeH",
        "outputId": "eff98ee5-1836-4fbe-9230-097dd9af1514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50647\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ]
        }
      ],
      "source": [
        "# train_mat_w2v,train_y=get_feature_dataset_train_w2v(train_tagged_sents)"
      ],
      "id": "5E5IGZ1zoZeH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f149bd9c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# #tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "# model=tf.keras.models.Sequential([\n",
        "#     #tf.keras.layers.LayerNormalization(),\n",
        "#     tf.keras.layers.Dense(64,activation='relu'),\n",
        "#     tf.keras.layers.LayerNormalization(),\n",
        "#     tf.keras.layers.Dense(12,activation=tf.keras.activations.softmax)\n",
        "# ])"
      ],
      "id": "f149bd9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4625049"
      },
      "outputs": [],
      "source": [
        "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"
      ],
      "id": "a4625049"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1529998"
      },
      "outputs": [],
      "source": [
        "# model.compile(optimizer='adam',\n",
        "#               loss=loss_fn,\n",
        "#               metrics=['accuracy'])"
      ],
      "id": "d1529998"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "08025554",
        "outputId": "fe0e664a-78a9-4b97-bda3-e15a096f003e"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-12dd036e6190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# SHUFFLE_BUFFER_SIZE = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_tf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    791\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m     \"\"\"\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4475\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4476\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4477\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4478\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m           \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    434\u001b[0m       \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m   \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m_type_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    906\u001b[0m   \u001b[0;31m# fallback).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0msubspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_type_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchableTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mmerged_subspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    906\u001b[0m   \u001b[0;31m# fallback).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0msubspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_type_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchableTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mmerged_subspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m_type_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    906\u001b[0m   \u001b[0;31m# fallback).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0msubspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_type_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchableTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mmerged_subspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    906\u001b[0m   \u001b[0;31m# fallback).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     \u001b[0msubspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_type_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchableTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mmerged_subspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m_type_spec_from_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# incompatible subspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_TYPE_CONVERSION_FUNCTION_REGISTRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m     \u001b[0mtype_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverter_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_subclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     if ((type(value) is type_object) or  # pylint: disable=unidiomatic-typecheck\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# BATCH_SIZE = 64\n",
        "# # SHUFFLE_BUFFER_SIZE = 100\n",
        "# train_tf_data = tf.data.Dataset.from_tensor_slices((train_mat, train_y)).batch(BATCH_SIZE)\n",
        "# model.fit(train_tf_data, epochs=10)"
      ],
      "id": "08025554"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxk9x1obsTQJ",
        "outputId": "29b72fcd-af7a-4918-e7b8-3c38b9caabbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "11014/11014 [==============================] - 30s 3ms/step - loss: 0.1845 - accuracy: 0.9382\n",
            "Epoch 2/10\n",
            "11014/11014 [==============================] - 30s 3ms/step - loss: 0.1492 - accuracy: 0.9466\n",
            "Epoch 3/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1422 - accuracy: 0.9481\n",
            "Epoch 4/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1383 - accuracy: 0.9490\n",
            "Epoch 5/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1358 - accuracy: 0.9496\n",
            "Epoch 6/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1338 - accuracy: 0.9501\n",
            "Epoch 7/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1323 - accuracy: 0.9504\n",
            "Epoch 8/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1310 - accuracy: 0.9507\n",
            "Epoch 9/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1300 - accuracy: 0.9510\n",
            "Epoch 10/10\n",
            "11014/11014 [==============================] - 29s 3ms/step - loss: 0.1291 - accuracy: 0.9512\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe19c546110>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# #w2v model\n",
        "# BATCH_SIZE = 64\n",
        "# # SHUFFLE_BUFFER_SIZE = 100\n",
        "# train_tf_data = tf.data.Dataset.from_tensor_slices((train_mat_w2v, train_y)).batch(BATCH_SIZE)\n",
        "# model.fit(train_tf_data, epochs=10)"
      ],
      "id": "kxk9x1obsTQJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32R6lvNqyhY3"
      },
      "outputs": [],
      "source": [
        "def sentence_decoding(training_sentences, test_sentences):\n",
        "    train_mat_w2v,train_y=get_feature_dataset_train_w2v(training_sentences)\n",
        "    train_mat_w2v=np.array(train_mat_w2v)\n",
        "    train_y=np.array(train_y)\n",
        "    print(\"training sets made ---------------------------------------\")\n",
        "    \n",
        "    #tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "    model=tf.keras.models.Sequential([\n",
        "        #tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(64,activation='relu'),\n",
        "        tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(12,activation=tf.keras.activations.softmax)\n",
        "    ])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "    BATCH_SIZE = 4\n",
        "    # SHUFFLE_BUFFER_SIZE = 100\n",
        "    print(\"starting making tf data\")\n",
        "    train_tf_data = tf.data.Dataset.from_tensor_slices((train_mat_w2v, train_y)).batch(BATCH_SIZE)\n",
        "    print(\"training started\")\n",
        "    model.fit(train_tf_data, epochs=5)\n",
        "    \n",
        "    test_mat_w2v,test_y=get_feature_dataset_train_w2v(test_sentences)\n",
        "    test_tf_data = tf.data.Dataset.from_tensor_slices(test_mat_w2v).batch(BATCH_SIZE)\n",
        "    one_hot_predictions=model.predict(test_tf_data)\n",
        "    predictions=[]\n",
        "    for i in range(len(one_hot_predictions)):\n",
        "        arr=one_hot_predictions[i].tolist()\n",
        "        \n",
        "        predictions.append(arr.index(max(arr)))\n",
        "\n",
        "    #print(\"test_y\",test_y)\n",
        "    #print(\"predictions\",predictions)\n",
        "    print(confusion_matrix(test_y,predictions))\n",
        "    return test_y, predictions"
      ],
      "id": "32R6lvNqyhY3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "132108fb"
      },
      "outputs": [],
      "source": [
        "def accuracy_per_fold(training_sentences, test_sentences):\n",
        "    test_y,predictions = sentence_decoding(training_sentences, test_sentences)\n",
        "    \n",
        "    f1 = 0\n",
        "    prec = 0\n",
        "    recall = 0\n",
        "    \n",
        "\n",
        "    #for i in range( len(actual_tags) ):\n",
        "    #    f1 += f1_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    prec += precision_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    recall += recall_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    per_pos=[[] for i in range(12)]\n",
        "    #per_pos_act=[[] for i in range(0,12)]\n",
        "    for i in range(len(test_y)):\n",
        "        per_pos[test_y[i]].append(predictions[i])\n",
        "    print(\"my_fold------------------------\")\n",
        "    for i in range(len(per_pos)):\n",
        "        print(i,\"-----\")\n",
        "        true_tag=[i for j in range(len(per_pos[i]))]\n",
        "        print(\"precision\",precision_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"recall\",recall_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"f1\",f1_score(per_pos[i],true_tag, average='weighted'))\n",
        "    print(\"overall for the batch:\")\n",
        "    precision=precision_score(test_y,predictions, average='weighted')\n",
        "    recall=recall_score(test_y,predictions, average='weighted')\n",
        "    f1=f1_score(test_y,predictions, average='weighted')\n",
        "    print(\"precision\",precision)\n",
        "    print(\"recall\",recall)\n",
        "    print(\"f1\",f1)\n",
        "\n",
        "        \n",
        "    return [precision, recall, f1]\n",
        "    #return [f1/len(actual_tags), prec/len(actual_tags), recall/len(actual_tags)]\n",
        "\n",
        "#total_acc_for_split1 = accuracy_per_fold(all_sentences[:57000], all_sentences[56000:56010])\n",
        "#total_acc_for_split2 = accuracy_per_fold(all_sentences[:57000], all_sentences[57000:57010])\n",
        "\n",
        "#print(\"\\nTotal accuracy for the above split1: \" + str(total_acc_for_split1))\n",
        "#print(\"Total accuracy for the above split2: \" + str(total_acc_for_split2) + \"\\n\")\n",
        "#exit(0)\n",
        "\n",
        "def cross_validation_accuracy(all_sentences = dataset):\n",
        "    all_accuracies = []\n",
        "    total_acc = [0, 0, 0]\n",
        "\n",
        "    num_sentences = len(dataset)\n",
        "\n",
        "    fold_size = int(num_sentences / 5)\n",
        "\n",
        "    print(fold_size)\n",
        "\n",
        "    fold1_train=dataset[:4*fold_size]\n",
        "    fold1_test=dataset[4*fold_size:]\n",
        "    fold2_train=dataset[:3*fold_size]+dataset[4*fold_size:]\n",
        "    fold2_test=dataset[3*fold_size:4*fold_size]\n",
        "    fold3_train=dataset[:2*fold_size]+dataset[3*fold_size:]\n",
        "    fold3_test=dataset[2*fold_size:3*fold_size]\n",
        "    fold4_train=dataset[:1*fold_size]+dataset[2*fold_size:]\n",
        "    fold4_test=dataset[1*fold_size:2*fold_size]\n",
        "    fold5_train=dataset[1*fold_size:]\n",
        "    fold5_test=dataset[:1*fold_size]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold1_train, fold1_test))\n",
        "    print(\"Accuracy for fold \", \"1\", \" is : \", str(all_accuracies[0]))\n",
        "    total_acc[0] += all_accuracies[0][0]\n",
        "    total_acc[1] += all_accuracies[0][1]\n",
        "    total_acc[2] += all_accuracies[0][2]\n",
        "\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold2_train, fold2_test))\n",
        "    print(\"Accuracy for fold \", \"2\", \" is : \", str(all_accuracies[1]))\n",
        "    total_acc[0] += all_accuracies[1][0]\n",
        "    total_acc[1] += all_accuracies[1][1]\n",
        "    total_acc[2] += all_accuracies[1][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold3_train, fold3_test))\n",
        "    print(\"Accuracy for fold \", \"3\", \" is : \", str(all_accuracies[2]))\n",
        "    total_acc[0] += all_accuracies[2][0]\n",
        "    total_acc[1] += all_accuracies[2][1]\n",
        "    total_acc[2] += all_accuracies[2][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold4_train, fold4_test))\n",
        "    print(\"Accuracy for fold \", \"4\", \" is : \", str(all_accuracies[3]))\n",
        "    total_acc[0] += all_accuracies[3][0]\n",
        "    total_acc[1] += all_accuracies[3][1]\n",
        "    total_acc[2] += all_accuracies[3][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold5_train, fold5_test))\n",
        "    print(\"Accuracy for fold \", \"5\", \" is : \", str(all_accuracies[4]))\n",
        "    total_acc[0] += all_accuracies[4][0]\n",
        "    total_acc[1] += all_accuracies[4][1]\n",
        "    total_acc[2] += all_accuracies[4][2]\n",
        "\n",
        "    print(\"Cross validation accuracy is : \", str(np.array(total_acc) / 5))"
      ],
      "id": "132108fb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "b4146e90",
        "outputId": "7ac78c9e-29e4-43b1-bad8-b896dedb776a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-020e01285662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_validation_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cross_validation_accuracy' is not defined"
          ]
        }
      ],
      "source": [
        "cross_validation_accuracy()"
      ],
      "id": "b4146e90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dijfzhjvFUN"
      },
      "source": [
        "Model for showing demo for word2vec"
      ],
      "id": "4dijfzhjvFUN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biz40uj1xrVA"
      },
      "outputs": [],
      "source": [
        "def sentence_decoding_model_save(training_sentences):\n",
        "    train_mat_w2v,train_y=get_feature_dataset_train_w2v(training_sentences)\n",
        "    \n",
        "    #tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "    model=tf.keras.models.Sequential([\n",
        "        #tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(64,activation='relu'),\n",
        "        tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(12,activation=tf.keras.activations.softmax)\n",
        "    ])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "    BATCH_SIZE = 64\n",
        "    # SHUFFLE_BUFFER_SIZE = 100\n",
        "    train_tf_data = tf.data.Dataset.from_tensor_slices((train_mat_w2v, train_y)).batch(BATCH_SIZE)\n",
        "    model.fit(train_tf_data, epochs=5)\n",
        "    model.save(\"demo_model.h5\")\n",
        "    #test_mat_w2v,test_y=get_feature_dataset_train_w2v(test_sentences)\n",
        "    #test_tf_data = tf.data.Dataset.from_tensor_slices(test_mat_w2v).batch(BATCH_SIZE)\n",
        "    #one_hot_predictions=model.predict(test_tf_data)\n",
        "    #predictions=[]\n",
        "    #for i in range(len(one_hot_predictions)):\n",
        "    #    arr=one_hot_predictions[i].tolist()\n",
        "        \n",
        "    #    predictions.append(arr.index(max(arr)))\n",
        "\n",
        "    #print(\"test_y\",test_y)\n",
        "    #print(\"predictions\",predictions)\n",
        "    #print(confusion_matrix(test_y,predictions))\n",
        "    return"
      ],
      "id": "biz40uj1xrVA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW5B6MYfvEjC"
      },
      "outputs": [],
      "source": [
        "sentence_decoding_model_save(dataset[:int(4/5*len(dataset))])"
      ],
      "id": "uW5B6MYfvEjC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxKklz4ty6fp"
      },
      "outputs": [],
      "source": [],
      "id": "qxKklz4ty6fp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAEV9YaVu8iz"
      },
      "source": [
        "Cross validation for FFNN model with engineered features"
      ],
      "id": "NAEV9YaVu8iz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_xd38ObI1o5"
      },
      "outputs": [],
      "source": [
        "def sentence_decoding(training_sentences, test_sentences):\n",
        "    train_mat,train_y=get_feature_dataset_train(training_sentences)\n",
        "    \n",
        "    #tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "    model=tf.keras.models.Sequential([\n",
        "        #tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(12,activation='relu'),\n",
        "        tf.keras.layers.LayerNormalization(),\n",
        "        tf.keras.layers.Dense(12,activation=tf.keras.activations.softmax)\n",
        "    ])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])\n",
        "    BATCH_SIZE = 64\n",
        "    # SHUFFLE_BUFFER_SIZE = 100\n",
        "    train_tf_data = tf.data.Dataset.from_tensor_slices((train_mat, train_y)).batch(BATCH_SIZE)\n",
        "    model.fit(train_tf_data, epochs=5)\n",
        "    \n",
        "    test_mat,test_y=get_feature_dataset_train(test_sentences)\n",
        "    test_tf_data = tf.data.Dataset.from_tensor_slices(test_mat).batch(BATCH_SIZE)\n",
        "    one_hot_predictions=model.predict(test_tf_data)\n",
        "    predictions=[]\n",
        "    for i in range(len(one_hot_predictions)):\n",
        "        arr=one_hot_predictions[i].tolist()\n",
        "        predictions.append(arr.index(max(arr)))\n",
        "\n",
        "    #print(\"test_y\",test_y)\n",
        "    #print(\"predictions\",predictions)\n",
        "    print(confusion_matrix(test_y,predictions))\n",
        "    return test_y, predictions"
      ],
      "id": "U_xd38ObI1o5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5bZFBo8JjE6"
      },
      "outputs": [],
      "source": [
        "def accuracy_per_fold(training_sentences, test_sentences):\n",
        "    test_y,predictions = sentence_decoding(training_sentences, test_sentences)\n",
        "\n",
        "    f1 = 0\n",
        "    prec = 0\n",
        "    recall = 0\n",
        "    \n",
        "\n",
        "    #for i in range( len(actual_tags) ):\n",
        "    #    f1 += f1_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    prec += precision_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    #    recall += recall_score(actual_tags[i], predicted_tags[i], average='weighted')\n",
        "    per_pos=[[] for i in range(12)]\n",
        "    #per_pos_act=[[] for i in range(0,12)]\n",
        "    for i in range(len(test_y)):\n",
        "        per_pos[test_y[i]].append(predictions[i])\n",
        "    print(\"my_fold------------------------\")\n",
        "    for i in range(len(per_pos)):\n",
        "        print(i,\"-----\")\n",
        "        true_tag=[i for j in range(len(per_pos[i]))]\n",
        "        print(\"precision\",precision_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"recall\",recall_score(per_pos[i],true_tag, average='weighted'))\n",
        "        print(\"f1\",f1_score(per_pos[i],true_tag, average='weighted'))\n",
        "    print(\"overall for the batch:\")\n",
        "    precision=precision_score(test_y,predictions, average='weighted')\n",
        "    recall=recall_score(test_y,predictions, average='weighted')\n",
        "    f1=f1_score(test_y,predictions, average='weighted')\n",
        "    print(\"precision\",precision)\n",
        "    print(\"recall\",recall)\n",
        "    print(\"f1\",f1)\n",
        "\n",
        "        \n",
        "    return [precision, recall, f1]\n",
        "    #return [f1/len(actual_tags), prec/len(actual_tags), recall/len(actual_tags)]\n",
        "\n",
        "#total_acc_for_split1 = accuracy_per_fold(all_sentences[:57000], all_sentences[56000:56010])\n",
        "#total_acc_for_split2 = accuracy_per_fold(all_sentences[:57000], all_sentences[57000:57010])\n",
        "\n",
        "#print(\"\\nTotal accuracy for the above split1: \" + str(total_acc_for_split1))\n",
        "#print(\"Total accuracy for the above split2: \" + str(total_acc_for_split2) + \"\\n\")\n",
        "#exit(0)\n",
        "\n",
        "def cross_validation_accuracy(all_sentences = dataset):\n",
        "    all_accuracies = []\n",
        "    total_acc = [0, 0, 0]\n",
        "\n",
        "    num_sentences = len(dataset)\n",
        "\n",
        "    fold_size = int(num_sentences / 5)\n",
        "\n",
        "    print(fold_size)\n",
        "\n",
        "    fold1_train=dataset[:4*fold_size]\n",
        "    fold1_test=dataset[4*fold_size:]\n",
        "    fold2_train=dataset[:3*fold_size]+dataset[4*fold_size:]\n",
        "    fold2_test=dataset[3*fold_size:4*fold_size]\n",
        "    fold3_train=dataset[:2*fold_size]+dataset[3*fold_size:]\n",
        "    fold3_test=dataset[2*fold_size:3*fold_size]\n",
        "    fold4_train=dataset[:1*fold_size]+dataset[2*fold_size:]\n",
        "    fold4_test=dataset[1*fold_size:2*fold_size]\n",
        "    fold5_train=dataset[1*fold_size:]\n",
        "    fold5_test=dataset[:1*fold_size]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold1_train, fold1_test))\n",
        "    print(\"Accuracy for fold \", \"1\", \" is : \", str(all_accuracies[0]))\n",
        "    total_acc[0] += all_accuracies[0][0]\n",
        "    total_acc[1] += all_accuracies[0][1]\n",
        "    total_acc[2] += all_accuracies[0][2]\n",
        "\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold2_train, fold2_test))\n",
        "    print(\"Accuracy for fold \", \"2\", \" is : \", str(all_accuracies[1]))\n",
        "    total_acc[0] += all_accuracies[1][0]\n",
        "    total_acc[1] += all_accuracies[1][1]\n",
        "    total_acc[2] += all_accuracies[1][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold3_train, fold3_test))\n",
        "    print(\"Accuracy for fold \", \"3\", \" is : \", str(all_accuracies[2]))\n",
        "    total_acc[0] += all_accuracies[2][0]\n",
        "    total_acc[1] += all_accuracies[2][1]\n",
        "    total_acc[2] += all_accuracies[2][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold4_train, fold4_test))\n",
        "    print(\"Accuracy for fold \", \"4\", \" is : \", str(all_accuracies[3]))\n",
        "    total_acc[0] += all_accuracies[3][0]\n",
        "    total_acc[1] += all_accuracies[3][1]\n",
        "    total_acc[2] += all_accuracies[3][2]\n",
        "\n",
        "    all_accuracies.append(accuracy_per_fold(fold5_train, fold5_test))\n",
        "    print(\"Accuracy for fold \", \"5\", \" is : \", str(all_accuracies[4]))\n",
        "    total_acc[0] += all_accuracies[4][0]\n",
        "    total_acc[1] += all_accuracies[4][1]\n",
        "    total_acc[2] += all_accuracies[4][2]\n",
        "\n",
        "    print(\"Cross validation accuracy is : \", str(np.array(total_acc) / 5))"
      ],
      "id": "_5bZFBo8JjE6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPI9BrjrJl7o",
        "outputId": "87be9ba6-0391-4ee7-81d9-e220a0a4759d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11468\n",
            "51461\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Epoch 1/5\n",
            "15307/15307 [==============================] - 45s 3ms/step - loss: 1.7465 - accuracy: 0.3613\n",
            "Epoch 2/5\n",
            "15307/15307 [==============================] - 40s 3ms/step - loss: 1.6939 - accuracy: 0.3735\n",
            "Epoch 3/5\n",
            "15307/15307 [==============================] - 40s 3ms/step - loss: 1.6842 - accuracy: 0.3788\n",
            "Epoch 4/5\n",
            "15307/15307 [==============================] - 40s 3ms/step - loss: 1.6771 - accuracy: 0.3841\n",
            "Epoch 5/5\n",
            "15307/15307 [==============================] - 40s 3ms/step - loss: 1.6732 - accuracy: 0.3859\n",
            "16747\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "[[28556     0     0   146     0    33   173     0    69     0   106     0]\n",
            " [  486     0     4   119     0  1345  4145     0   103     0  3653     0]\n",
            " [  842     0   111    68     0  3300  5606     0   519     0  7988     0]\n",
            " [  939     0    12   395     0  1285  4171     0   503     0  2994     0]\n",
            " [  765     0     5    61     0   952  2499     0  1110     0   582     0]\n",
            " [ 1061     0   119    70     0  5317  5673     0  1184     0  6606     0]\n",
            " [ 2726     0    20   383     3  3634 19091     0   791     0  7382     0]\n",
            " [  123     0     1     8     0   181   272     0    67     0   420     0]\n",
            " [  762     0     4    16     0  1726  5807     0  1624     0  3845     0]\n",
            " [  348     0     2    79     0  1504  2122     0   386     0  2072     0]\n",
            " [ 1654     0    28   189     0  5071 10648     0   424     0 14277     0]\n",
            " [   31     0     0     8     0     9    94     0     5     0    34     0]]\n",
            "my_fold------------------------\n",
            "0 -----\n",
            "precision 0.9640872513376766\n",
            "recall 0.9818794484750542\n",
            "f1 0.972902011854947\n",
            "1 -----\n",
            "precision 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recall 0.0\n",
            "f1 0.0\n",
            "2 -----\n",
            "precision 3.6258246006805e-05\n",
            "recall 0.0060214820440490395\n",
            "f1 7.208244884221553e-05\n",
            "3 -----\n",
            "precision 0.001470970878773983\n",
            "recall 0.03835323817846393\n",
            "f1 0.002833276431736161\n",
            "4 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "5 -----\n",
            "precision 0.07046466994465865\n",
            "recall 0.2654518222666001\n",
            "f1 0.11136681571716675\n",
            "6 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.3147266050793197\n",
            "recall 0.5610049955921246\n",
            "f1 0.4032358717211367\n",
            "7 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "8 -----\n",
            "precision 0.013881024505773346\n",
            "recall 0.11781775972141613\n",
            "f1 0.02483593481147194\n",
            "9 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "10 -----\n",
            "precision 0.19548387072457873\n",
            "recall 0.4421355795732557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 0.271103318569291\n",
            "11 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "overall for the batch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.32325833738670573\n",
            "recall 0.38211252244610183\n",
            "f1 0.3168214594672889\n",
            "Accuracy for fold  1  is :  [0.32325833738670573, 0.38211252244610183, 0.3168214594672889]\n",
            "51034\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Epoch 1/5\n",
            "14912/14912 [==============================] - 38s 3ms/step - loss: 1.7658 - accuracy: 0.3579\n",
            "Epoch 2/5\n",
            "14912/14912 [==============================] - 38s 3ms/step - loss: 1.7016 - accuracy: 0.3808\n",
            "Epoch 3/5\n",
            "14912/14912 [==============================] - 39s 3ms/step - loss: 1.6922 - accuracy: 0.3830\n",
            "Epoch 4/5\n",
            "14912/14912 [==============================] - 38s 3ms/step - loss: 1.6834 - accuracy: 0.3865\n",
            "Epoch 5/5\n",
            "14912/14912 [==============================] - 39s 3ms/step - loss: 1.6749 - accuracy: 0.3908\n",
            "19307\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "[[26213     0     0     1     1  1348   208     0    28     0   111     0]\n",
            " [  341     0   602    31     1  1697  5025     0   201     0  5340     0]\n",
            " [  317     0  1513    12     6  4083  4288     0   877     0 13357     0]\n",
            " [  618     0   529   112     0  1750  2984     0   459     0  4383     0]\n",
            " [  227     0    86    11     7  1663  2281     0   802     0  1479     0]\n",
            " [  259     0  2458     5     2  6753  6155     0  1288     0  7331     0]\n",
            " [ 3348     0  1581    71    15  4310 21916     0  1121     0 13223     0]\n",
            " [  912     0   121     0     0   227   314     0    79     0   561     0]\n",
            " [   76     0   454     1     9  1986  2600     0  1944     0  3601     0]\n",
            " [  105     0   656     8     2  1381  1118     0   342     0  2543     0]\n",
            " [  351     0  1824     6     8  4703  7409     0   405     0 20090     0]\n",
            " [   90     0     0     0     0     7    66     0     3     0    49     0]]\n",
            "my_fold------------------------\n",
            "0 -----\n",
            "precision 0.8820917942596109\n",
            "recall 0.9391974202794697\n",
            "f1 0.9097493478848453\n",
            "1 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "2 -----\n",
            "precision 0.003828366967536201\n",
            "recall 0.061873798715903976\n",
            "f1 0.007210587495737712\n",
            "3 -----\n",
            "precision 0.00010685090725100189\n",
            "recall 0.010336871250576835\n",
            "f1 0.00021151540697261447\n",
            "4 -----\n",
            "precision 1.1400350144305168e-06\n",
            "recall 0.0010677242220866383\n",
            "f1 2.277638139450394e-06\n",
            "5 -----\n",
            "precision 0.07754149968706332\n",
            "recall 0.2784627438043792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 0.12130427744232826\n",
            "6 -----\n",
            "precision 0.23114189274697597\n",
            "recall 0.480772183832401\n",
            "f1 0.3121910247513637\n",
            "7 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "8 -----\n",
            "precision 0.033188091698163696\n",
            "recall 0.18217599100365475\n",
            "f1 0.056147463576869575\n",
            "9 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "10 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.33335059079045004\n",
            "recall 0.5773652143924589\n",
            "f1 0.42266760766477796\n",
            "11 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "overall for the batch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.3283861343839016\n",
            "recall 0.37968087626100283\n",
            "f1 0.32806229271123977\n",
            "Accuracy for fold  2  is :  [0.3283861343839016, 0.37968087626100283, 0.32806229271123977]\n",
            "48859\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Epoch 1/5\n",
            "13873/13873 [==============================] - 36s 3ms/step - loss: 1.7498 - accuracy: 0.3676\n",
            "Epoch 2/5\n",
            "13873/13873 [==============================] - 36s 3ms/step - loss: 1.6946 - accuracy: 0.3835\n",
            "Epoch 3/5\n",
            "13873/13873 [==============================] - 35s 3ms/step - loss: 1.6877 - accuracy: 0.3841\n",
            "Epoch 4/5\n",
            "13873/13873 [==============================] - 36s 3ms/step - loss: 1.6843 - accuracy: 0.3853\n",
            "Epoch 5/5\n",
            "13873/13873 [==============================] - 36s 3ms/step - loss: 1.6814 - accuracy: 0.3861\n",
            "22557\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "[[28929     0    27     0    26   356   806     0   113     0   463     0]\n",
            " [  268     0  1183     9    26  4057  7260     0   287     0  8913     0]\n",
            " [  136     0  1410     0   160  9521  7674     0  1184     0 18471     0]\n",
            " [   40     0   483   114    12  3610  3205     0   408     0  4233     0]\n",
            " [  131     0   120    16   140  2443  2762     0   679     0  3027     0]\n",
            " [  130     0  2398    12   134 13117  6689     0  1181     0  9238     0]\n",
            " [ 2142     0  2921    48    90  8308 33258     0   822     0 20881     0]\n",
            " [ 2238     0   111     1     3   611   450     0   105     0   979     0]\n",
            " [    1     0   276     6     5  2691  1839     0  1043     0  2228     0]\n",
            " [   14     0   373     1    17  2919   785     0   119     0  1457     0]\n",
            " [   25     0  1522     5    18  8507 11724     0   204     0 18530     0]\n",
            " [   18     0    12     1     1    87   165     0     7     0   154     0]]\n",
            "my_fold------------------------\n",
            "0 -----\n",
            "precision 0.8867974185943603\n",
            "recall 0.94169921875\n",
            "f1 0.9134240875528089\n",
            "1 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "2 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.001337378330659303\n",
            "recall 0.03657018362900716\n",
            "f1 0.002580391278431672\n",
            "3 -----\n",
            "precision 8.869111507272948e-05\n",
            "recall 0.009417596034696406\n",
            "f1 0.00017572730140852613\n",
            "4 -----\n",
            "precision 0.0002257411115243555\n",
            "recall 0.01502468340845675\n",
            "f1 0.00044479925506110067\n",
            "5 -----\n",
            "precision 0.15896577894632244\n",
            "recall 0.3987051278154351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1 0.2273042055613292\n",
            "6 -----\n",
            "precision 0.2359345820856195\n",
            "recall 0.48573097707024976\n",
            "f1 0.31760067700932615\n",
            "7 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "8 -----\n",
            "precision 0.01662566196092577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recall 0.1289405365310916\n",
            "f1 0.029453565396830608\n",
            "9 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "10 -----\n",
            "precision 0.2089731474682651\n",
            "recall 0.4571358085605033\n",
            "f1 0.28682727614073056\n",
            "11 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "overall for the batch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.31790477827433217\n",
            "recall 0.3532121336294421\n",
            "f1 0.30738130449353224\n",
            "Accuracy for fold  3  is :  [0.31790477827433217, 0.3532121336294421, 0.30738130449353224]\n",
            "48535\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Epoch 1/5\n",
            "14252/14252 [==============================] - 37s 3ms/step - loss: 1.7601 - accuracy: 0.3628\n",
            "Epoch 2/5\n",
            "14252/14252 [==============================] - 36s 3ms/step - loss: 1.7018 - accuracy: 0.3805\n",
            "Epoch 3/5\n",
            "14252/14252 [==============================] - 37s 3ms/step - loss: 1.6934 - accuracy: 0.3848\n",
            "Epoch 4/5\n",
            "14252/14252 [==============================] - 37s 3ms/step - loss: 1.6872 - accuracy: 0.3880\n",
            "Epoch 5/5\n",
            "14252/14252 [==============================] - 37s 3ms/step - loss: 1.6814 - accuracy: 0.3909\n",
            "24031\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "[[28309     0     0     3    46   198   733     0    52     0   396     0]\n",
            " [  421     0   164    17    25  1445  5724     0   420     0 11468     0]\n",
            " [  149     0   453    15    79  2406  6772     0  1533     0 20868     0]\n",
            " [   85     0   114   126    39  1235  3174     1   796     0  6459     0]\n",
            " [  140     0    93     7   313   321  3606     0  1067     0  3094     0]\n",
            " [  179     0   125    12   212  4943  9713     0  2229     0 12971     0]\n",
            " [ 1898     0   138    60   175  2662 28128    69  1090     0 26463     0]\n",
            " [ 1220     0    15     0     2   236   337     0   142     0  1164     0]\n",
            " [   39     0   201     5    43  1302  1800     0  1251     0  3945     0]\n",
            " [   20     0     6     9    19   715  1655     0   301     0  2960     0]\n",
            " [   64     0   358    11    80  2202 10425     0   852     0 24008     0]\n",
            " [   20     0     0     0     5    12   129     0     2     0    96     0]]\n",
            "my_fold------------------------\n",
            "0 -----\n",
            "precision 0.9062640469816723\n",
            "recall 0.9519790160406227\n",
            "f1 0.9285592104570166\n",
            "1 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "2 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.00019699894580906606\n",
            "recall 0.014035631293570876\n",
            "f1 0.0003885444253231244\n",
            "3 -----\n",
            "precision 0.0001097190504663471\n",
            "recall 0.010474686175076898\n",
            "f1 0.00021716338265070987\n",
            "4 -----\n",
            "precision 0.001312081055053043\n",
            "recall 0.03622265941441963\n",
            "f1 0.002532430734132978\n",
            "5 -----\n",
            "precision 0.026466183916606427\n",
            "recall 0.1626843075302791\n",
            "f1 0.045526001761948064\n",
            "6 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.21485408774985598\n",
            "recall 0.4635235568445858\n",
            "f1 0.29361206622883446\n",
            "7 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "8 -----\n",
            "precision 0.021229161996932255\n",
            "recall 0.14570230607966456\n",
            "f1 0.03705877501385796\n",
            "9 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "10 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.39915793905817176\n",
            "recall 0.6317894736842106\n",
            "f1 0.48922725081313784\n",
            "11 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "overall for the batch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.3380998011389696\n",
            "recall 0.35141157199980727\n",
            "f1 0.2963897346231586\n",
            "Accuracy for fold  4  is :  [0.3380998011389696, 0.35141157199980727, 0.2963897346231586]\n",
            "47402\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "Epoch 1/5\n",
            "14232/14232 [==============================] - 37s 3ms/step - loss: 1.7780 - accuracy: 0.3537\n",
            "Epoch 2/5\n",
            "14232/14232 [==============================] - 37s 3ms/step - loss: 1.7124 - accuracy: 0.3689\n",
            "Epoch 3/5\n",
            "14232/14232 [==============================] - 37s 3ms/step - loss: 1.6982 - accuracy: 0.3754\n",
            "Epoch 4/5\n",
            "14232/14232 [==============================] - 37s 3ms/step - loss: 1.6930 - accuracy: 0.3778\n",
            "Epoch 5/5\n",
            "14232/14232 [==============================] - 37s 3ms/step - loss: 1.6902 - accuracy: 0.3787\n",
            "25028\n",
            "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n",
            "[[28008     0    12     0     7   470   783     0   106     0   729     0]\n",
            " [  453     0  1607     0     3  2703 10724     0   402     0  3049     0]\n",
            " [  145     0  2290     0   122  5629 16387     0  1204     0  5271     0]\n",
            " [   70     0  1016     0    22  1972  5639     0   541     0  1711     0]\n",
            " [   59     0   152     0    99   870  3803     0  1019     0  1660     0]\n",
            " [  325     0  4027     0   106  8692 11450     0  1988     0  2867     0]\n",
            " [ 1197     0  3569     0    12  6446 45187     0  1334     0  9045     0]\n",
            " [ 1856     0   204     0    10   476   991     0   138     0   299     0]\n",
            " [    8     0   771     0     0  1891  3253     0  1280     0  1001     0]\n",
            " [   13     0   956     0    24  1950  2040     0   225     0   583     0]\n",
            " [   79     0  2430     0    16  5461 19411     0   569     0  9162     0]\n",
            " [    9     0     6     0     0    26   185     0     3     0    52     0]]\n",
            "my_fold------------------------\n",
            "0 -----\n",
            "precision 0.8649648526186174\n",
            "recall 0.9300348663456749\n",
            "f1 0.896320442393189\n",
            "1 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "2 -----\n",
            "precision 0.005440060194549772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recall 0.07375676372069054\n",
            "f1 0.010132760748718057\n",
            "3 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "4 -----\n",
            "precision 0.00016694987333885642\n",
            "recall 0.012920908379013312\n",
            "f1 0.00032964049208151466\n",
            "5 -----\n",
            "precision 0.08708059366616662\n",
            "recall 0.29509421150908166\n",
            "f1 0.13447762007166686\n",
            "6 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.4577244709205921\n",
            "recall 0.6765533762539302\n",
            "f1 0.5460302993076497\n",
            "7 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "8 -----\n",
            "precision 0.024342693780560597\n",
            "recall 0.1560214529497806\n",
            "f1 0.042114605604327116\n",
            "9 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "10 -----\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.06089441519733546\n",
            "recall 0.24676793794440854\n",
            "f1 0.09768363998473412\n",
            "11 -----\n",
            "precision 0.0\n",
            "recall 0.0\n",
            "f1 0.0\n",
            "overall for the batch:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "precision 0.30006113800470013\n",
            "recall 0.3783272088193002\n",
            "f1 0.32317782433718273\n",
            "Accuracy for fold  5  is :  [0.30006113800470013, 0.3783272088193002, 0.32317782433718273]\n",
            "Cross validation accuracy is :  [0.32154204 0.36894886 0.31436652]\n"
          ]
        }
      ],
      "source": [
        "cross_validation_accuracy()"
      ],
      "id": "JPI9BrjrJl7o"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}